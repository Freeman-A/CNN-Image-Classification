{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **About Notebook**\n","\n","\n","This notebook contains the testing of 3 unique image classification models inlcuding ResNet50, EfficentNet50 , and InceptionV3. \n","\n","Each model will be tested and evaluated using XAI and standard evaluation tecniques. Attempts will be made to make this as reproduceable as possible, in adittion to this, models will use as similar Tuning as possible to make the comparison fair and consistent; but changes will be made where necssary to ensure model tranining can persist.\n","\n","A list of the models used and their performance accuracy will be below. \n","\n","## **Models Overview**\n","\n","* ResNet50 shows a balanced yet low performance with an overall accuracy of 64.26%. It struggles with correctly identifying 'Normal' cases but performs well with 'Pneumonia' cases.\n","\n","* EfficientNetB0 has an overall accuracy of 62.50%. It completely fails to identify 'Normal' cases while perfectly identifying 'Pneumonia' cases.\n","\n","* InceptionV3 is the best-performing model with a validation accuracy of 77.08%. It shows a better balance between identifying 'Normal' and 'Pneumonia' cases compared to the other models, though it still has room for improvement in reducing false negatives for 'Pneumonia'.\n","\n","### **Models Can be Found Here** \n","[Keras Applications](https://keras.io/api/applications/)\n","\n","[Pytorch Image Models](https://paperswithcode.com/lib/timm)\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["## **Import Packages & Libraries**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Importing necessary packages and libraries\n","\n","# Operating system interface for file and directory management\n","import os \n","\n","# Base python library for randomisation of data\n","import random\n","\n","# Numerical and data manipulation libraries\n","import numpy as np \n","import pandas as pd \n","import cv2  # OpenCV for image processing\n","\n","# Visualisation Package for Data insights\n","import matplotlib.pyplot as plt\n","\n","# TensorFlow Keras modules for deep learning model building and preprocessing\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow import data as tf_data\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.applications import ResNet50, EfficientNetB0, InceptionV3\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.imagenet_utils import decode_predictions, preprocess_input\n","from tensorflow.keras.preprocessing import image as keras_image\n","import matplotlib.patches as patches\n","\n","from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n","\n","# Packages for visualising model Evaluations\n","from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n","from skimage.segmentation import mark_boundaries\n","from skimage import io\n","from lime import lime_image"]},{"cell_type":"markdown","metadata":{},"source":["## **Data Directories**\n","\n","Relevent Links for coding insperation\n","\n","[tf.keras.preprocessing.image_dataset_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory)\n","\n","[flow_from_directory](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Paths to sets within the directories\n","train_path = '/kaggle/input/chest_xray/train'\n","test_path = '/kaggle/input/chest_xray/test'\n","val_path = '/kaggle/input/chest_xray/val'"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Define the data augmentation model\n","data_augmentation = tf.keras.Sequential([\n","    tf.keras.layers.RandomFlip(\"horizontal\"),\n","    tf.keras.layers.RandomRotation(0.2),\n","])\n","\n","# Optimize data loading\n","def load_data(directory, img_size=(150, 125), batch_size=32, augment=False):\n","    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n","        directory,\n","        labels='inferred',\n","        label_mode='binary',\n","        color_mode='rgb',\n","        image_size=img_size,\n","        batch_size=batch_size,\n","        crop_to_aspect_ratio=True, \n","        seed=42\n","    )\n","\n","    if augment:\n","        # Augment the train dataset to prevent overfitting\n","        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y))\n","    \n","    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n","    return dataset"]},{"cell_type":"markdown","metadata":{},"source":["## **Make Training Sets**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_ds = load_data(train_path, augment=True)\n","test_ds = load_data(test_path)\n","val_ds = load_data(val_path)"]},{"cell_type":"markdown","metadata":{},"source":["## **Train Model Functions for Simplicity**\n","\n","[Call Backs from keras](https://keras.io/guides/writing_your_own_callbacks/)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Stop training early if 'val_loss' doesn't improve for 6 epochs\n","# Also, restore the best model weights from the epoch with the lowest 'val_loss'\n","early_stopping = EarlyStopping(monitor='val_loss', patience=6, restore_best_weights=True)\n","\n","# Reduce learning rate when 'val_loss' stops improving\n","# Reduce the learning rate by a factor of 0.2 after 3 epochs of no improvement\n","reduced_plateau = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.001) \n","\n","callbacks = [early_stopping, reduced_plateau]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def train_top_layers(model, train_generator, val_generator):\n","    \"\"\"\n","    model that can be used to simplify training models based on keras typical transfering workflow tranining\n","    \n","    Args: \n","        Model: the model that you wish to use to train\n","        train_generator: you x_train data either exclusively x_train data or a training dataset\n","        val_generator: the validation data set to compare with the train set\n","        \n","    Returns: \n","        history: for model evaluation \n","    \n","    \"\"\"\n","    \n","    model.compile(optimizer=keras.optimizers.Adam(),\n","              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","              metrics=[keras.metrics.BinaryAccuracy()])\n","    \n","    history = model.fit(\n","        train_generator,\n","        epochs=2, \n","        validation_data=val_generator, \n","        callbacks=callbacks\n","    )\n","    \n","    return history"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def fine_tune(model, train_generator, val_generator): \n","    \"\"\"\n","    used to further imporove a trained mode\n","    Args: \n","        model: the tranining model\n","        train_generator: the tranining dataset\n","        val_data: the set to compare agains the train set\n","        \n","    Returns: \n","        history: for model evaluation \n","    \n","    \"\"\"\n","    model.trainable = True\n","\n","    model.compile(\n","        optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n","        loss=keras.losses.BinaryCrossentropy(from_logits=True),\n","        metrics=[keras.metrics.BinaryAccuracy()],\n","    )\n","\n","\n","    history = model.fit(\n","        train_generator, \n","        epochs=12, \n","        validation_data=val_generator, \n","        callbacks=callbacks)\n","    \n","    return history"]},{"cell_type":"markdown","metadata":{},"source":["# **Models**\n","\n","These models are all trained based on the keras typical transfer-learning workflow exmaple to keep the test fair \n","\n","Typical transfer-learning workflow: [The typical transfer-learning workflow](https://keras.io/guides/transfer_learning/)"]},{"cell_type":"markdown","metadata":{},"source":["## **Basic Model Building Function**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_model(base_model, img_size=(150, 125, None), num_classes=1):\n","    \"\"\"\n","    Simple function based on keras typical transfering workflow tranining to make it easier to implement existing models\n","    \n","    Args: \n","        base_model: the model that  you wish to build the structure for\n","        img_size: ideally this would be done in your preprocessing but you can use this to format the image sizes\n","        num_classes: the classes used for the model architechture\n","        \n","    Returns: \n","        model: the built model ready for tranining\n","    \"\"\"\n","    base_model.trainable = False  # Freeze the base model\n","    inputs = keras.Input(shape=img_size)\n","    scale_layer = keras.layers.Rescaling(scale=1/127.5, offset=-1)  # Normalize input\n","    x = scale_layer(inputs)\n","    x = base_model(x, training=False)  # Ensure base model runs in inference mode\n","    x = keras.layers.GlobalAveragePooling2D()(x)\n","    x = keras.layers.Dropout(0.2)(x)  # Regularize with dropout\n","    outputs = keras.layers.Dense(num_classes, activation='sigmoid' if num_classes == 1 else 'softmax')(x)  # Adjust for binary or multi-class classification\n","    model = keras.Model(inputs, outputs)\n","    return model"]},{"cell_type":"markdown","metadata":{},"source":["## **Evaluation Functions**\n","\n","Here are some functions to simplify to reproduce easy evaluation techniques for the models."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def generate_confusion_matrix(model, test_generator): \n","    \"\"\"\n","    generates a confusion matrix and displays the matrix plot\n","    Args: \n","        model: the model that is being tested\n","        test_generator: the test dataset\n","        \n","    \"\"\"\n","    \n","    # Generate predictions\n","    true_labels  = np.concatenate([y for x, y in test_generator], axis=0)\n","    predicted_labels  = np.concatenate([model.predict(x) for x, y in test_generator], axis=0)\n","    predicted_labels  = np.round(predicted_labels).astype(int)\n","\n","    # Compute confusion matrix\n","    confusion_mtx  = confusion_matrix(true_labels, predicted_labels)\n","    display  = ConfusionMatrixDisplay(confusion_matrix=confusion_mtx, display_labels=['Normal', 'Pneumonia'])\n","\n","    # Display confusion matrix\n","    display.plot(cmap='Blues')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## **ResNet50**\n","\n","The ResNet50 employs residual blocks that use shortcut connections to jump over some layers. This design helps mitigate the vanishing gradient problem, making it easier to train very deep networks. ResNet50 uses 50 layers, hence the name ResNet50, the user of more layers leads to deeper networks, designed to extract hierarchical features through the layers.\n","\n","Read more about the ResNet Architechture here: [ResNet and ResNetV2](https://keras.io/api/applications/resnet/)\n","\n","### **Build Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# The base model for ResNet50 \n","base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(150, 125, 3))\n","    \n","# The built model from the function build_model\n","resnet50_model = build_model(base_model)"]},{"cell_type":"markdown","metadata":{},"source":["### **Train Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# First itteration of tranining for the ResNet50 model\n","resnet50_model_history = train_top_layers(resnet50_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["### **Fine Tune ResNet50 Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Fine Tuning the model with the fine_tune function to enhance its performance\n","resnet50_model_history = fine_tune(resnet50_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["The ResNet50 model demonstrated strong training performance with nearly 100% accuracy on the training set. However, the evaluation has revealed a lower test accuracy of 81.56%, highlighting issues with overfitting and misclassification. The confusion matrix further elucidates the model's tendency to misclassify normal cases as pneumonia, indicating a need for improved specificity. Further fine-tuning an validation would enhance the model's robustness and reduce misclassification.\n","\n","---"]},{"cell_type":"markdown","metadata":{},"source":["## **EfficientNetB0 Model**\n","\n","Unlike ResNet50 EfficientNetB0 uses compound scaling that uniformly scales the network's width, depth and resolution using a set of fixed coefficients. This method allows, EfficientNet to achieve better performance with fewer parameters. It is also designed to be computationally efficient, striking a balance between performance and resource usage. This makes it suitable for environments with limited computational resources.\n","\n","Read About Model Scaling for Convolution Neural Networks here: [EfficientNet](https://arxiv.org/pdf/1905.11946)\n","\n","### **Build Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Base model for the EfficientNetB0 build\n","base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(150, 125, 3))\n","\n","# Built EfficientNetb0 model\n","efficientNetB0_model = build_model(base_model)"]},{"cell_type":"markdown","metadata":{},"source":["### **Train Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Itteration one of traning the EfficientNet model\n","efficientNetB0_model_history = train_top_layers(efficientNetB0_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["### **Fine Tune EfficientNetB0 Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Fine tuning the moderl for improved performance\n","efficientNetB0_model_history = fine_tune(efficientNetB0_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["## **Inceptionv3 Model**\n","\n","InceptionV3 uses a network-in-network out approach with mixed convolutions in the same layer, allowing it to capture multi-scale features effectively. It was designed to be computationally efficient while maintaining high accuracy, similar to EfficentNetB0 but using a different architectural approach. The combination of mixed convolutions, factorized convolutions, an auxiliary classifier for enhanced performance and training efficiency.\n","\n","Read more about InceptionV3 here: [Inception V3 Model Architecture\n","](https://iq.opengenus.org/inception-v3-model-architecture/)\n","\n","### **Build Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Base model for the InceptionV3 build\n","base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 125, 3))\n","\n","# Built EfficientNetb0 model\n","inceptionv3_model = build_model(base_model)"]},{"cell_type":"markdown","metadata":{},"source":["### **Train Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Itteration one of traning the InceptionV3 model\n","inceptionv3_model_history = train_top_layers(inceptionv3_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["### **Fine Tune Model**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Fine tuning the InceptionV3 model for improved performance\n","inceptionv3_model_history = fine_tune(inceptionv3_model, train_ds, val_ds)"]},{"cell_type":"markdown","metadata":{},"source":["## **Evaluation of Models**\n","\n","Here we compare the architectures and performances of three models: ResNet50, EfficientNetB0, and InceptionV3. ResNet50 and InceptionV3 have significantly more parameters than EfficientNetB0, resulting in varied performance during training and validation. InceptionV3 achieved the highest training and validation accuracy, indicating better generalization, while EfficientNetB0 struggled the most, exhibiting the highest validation loss and the lowest accuracy. ResNet50 performed moderately, with accuracy between that of EfficientNetB0 and InceptionV3.\n","\n","The confusion matrix analysis revealed that both ResNet50 and EfficientNetB0 had difficulties in correctly predicting 'Normal' cases, showing a high number of false positives for pneumonia. EfficientNetB0 failed to predict any 'Normal' cases correctly, and ResNet50 had very few correct predictions. In contrast, InceptionV3 demonstrated a better balance, correctly predicting a significant number of both 'Normal' and 'Pneumonia' cases, though it still had notable false negatives and false positives.\n","\n","ResNet50 and EfficientNetB0 might be overfitting on 'Pneumonia' cases due to the imbalance in predicting 'Normal' cases accurately. InceptionV3, with its deeper and more complex architecture, captures more nuanced features, leading to superior performance. However, there is still room for improvement, especially in reducing false negatives for 'Pneumonia'.\n","\n","In conclusion, InceptionV3 is the most promising model among the three, with the highest validation accuracy and a better confusion matrix profile. ResNet50 is a decent performer but needs improvements in handling 'Normal' cases, whereas EfficientNetB0 underperformed, suggesting it may require further tuning or data augmentation to be suitable for this specific task. Enhancements could include techniques like data augmentation, class rebalancing, fine-tuning pre-trained weights, and exploring different network architectures."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Dictionary of model names and their corresponding models\n","models = {'ResNet50': resnet50_model, 'EfficentNetB0': efficientNetB0_model, 'InceptionV3': inceptionv3_model}\n","\n","# Iterate through each model in the dictionary\n","for model_name, model in models.items():\n","    # Print the summary of the current model\n","    model.summary()\n","\n","    # Evaluate the model on the test dataset and print the validation loss and accuracy\n","    validation_loss, validation_accuracy = model.evaluate(test_ds)\n","    print(f'\\n Validation Loss: {validation_loss}  Validation Accuracy: {validation_accuracy*100:.2f} %\\n')\n","\n","    # Generate and print the confusion matrix for the current model\n","    print(f'\\nHere is a confusion matrix for {model_name}\\n')\n","    generate_confusion_matrix(model, test_ds)\n","    \n","    # Print a separator for better readability\n","    print('\\n--------------------------------------------------------\\n')"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":17810,"sourceId":23812,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
